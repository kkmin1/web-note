{
  "id": "21f82870-3834-45b2-8b87-1d1f10892674",
  "title": "인공지능(AI)과 수학",
  "content": "AI에서 수학이 활용되는 이유가 뭘까? AI 알고리즘을 굳이 수학으로 표현하는 이유는 무엇인가?\nAI가 사람의 사고를 흉내 내는 기술이기 때문이라고 말할 수 있다. AI 알고리즘에 적용된 수학은 부차적인 문제일 뿐이다. \n좀 더 명확히 이해하기 위해 일반 시스템과 AI 시스템의 구현 방법을 살펴보자. AI가 적용되지 않은 일반 시스템은 사람의 코딩에 의해서 구현된다. 다시 말해 사람이 시스템 동작 규칙을 코딩으로 정의한다. 반면 AI 시스템에서는 사람이 코딩으로 동작 원리를 정의하지 않는다. 사람은 AI가 이해할 수 있는 데이터 제공과 학습하는 방법론을 정할 뿐이다. AI는 이를 기반으로 동작 규칙을 스스로 만들어낸다.\n두 시스템에서 눈여겨볼 점은 “동작 규칙을 누가 만들어 내느냐”이다. 일반 시스템에서는 사람이 만들어낸다. 다시 말해 사람이 정한대로만 움직이다. 이러한 이유로 해당 시스템을 규칙 기반(Rule-based)라고 표현하기도 한다.\n반면 AI 시스템은 스스로 동작 규칙을 정한다. 그리고 이러한 규칙은 학습에 의해서 스스로 개선한다. 참고로 AI에서는 이러한 규칙을 생각으로 묘사하는 경우가 많다. 이유는 사람처럼 학습하고 가치관을 확립하기 때문이다.\n수학은 세상을 숫자로 표현하는 학문이다. 그리고 숫자는 측정에 있어 정확한 기준을 제시할 수 있다. 키 큰 사람보다는 190센티미터의 키를 가진 사람이라고 표현하면서 정확한 측정값을 나타낼 수 있다. 수학은 이러한 숫자를 통해서 세상의 법칙을 정확하게 표현할 수 있고, 판단의 근거를 제시할 수 있다. 예를 들어 수학은 가장 기초적인 합산의 법칙에서부터 물체의 운동 그리고 양자 이론의 법칙까지 설명할 수 있게 한다. 또한 수학은 경제와 재무에 활용되어 사업가에게 사업의 판단 기준을 제시해 주기도 한다.\nAI에 수학이 필요한 이유가 무엇일까? AI 시스템은 사람의 생각을 흉내 낸다고 정의할 수 있다. 그럼 AI는 사람의 어떤 생각을 따라 해야 할까? 합리성을 따라야 한다. 그리고 AI는 사람처럼 실수하면 안 될 정도로 여러 중요 분야에 활용되기 때문에 정량적으로 매우 정확하게 생각해야 한다. 이때 수학이 필요한 것이다.\n\n사람은 일상에서 수학 공식을 활용하지 않는다. 직관(사실은 뇌는 수학적 원리에 의해 작동)이라는 것에 의존한다. 반면 AI에서는 직관을 기대하기 어렵다. 대신에 사람이 수학으로 법칙을 표현하거나 수학에 근거하여 판단하는 것에 착안해 AI에 이러한 직관 혹은 생각을 심어줄 수 있다.\n\n바둑을 잘 두는데 있어서 수학은 필요하지 않다. 그러나 바둑 인공지능은 수학적 최적화 모형으로 구성된다. 인간의 직관 또는 감각이란 반복된 경험에서 오는 최적화의 결과일 뿐이다.\n\n\n인공지능 모델도 학습을 하기 위해서는 데이터가 필요합니다. 그러나 사람의 뇌는 이미지, 텍스트, 음성 등 다양한 형태의 데이터를 바로 이해할 수 있지만, 컴퓨터는 그렇지 못하기 때문에 인공지능 모델에 데이터를 사용할 때는 데이터를 컴퓨터가 이해할 수 있는 형태로 변환해줘야 합니다.  그렇기 때문에 인공지능에서 데이터는 여러 숫자들이 나열된 ‘배열’ 형태로 표현됩니다. 이미지 데이터는 픽셀 값들을 포함하는 다차원 배열이 되며, 텍스트와 음성 데이터도 전처리 과정을 거쳐서 숫자들의 배열로 표현됩니다.\n이러한 숫자 배열이 바로 선형대수학에서 등장하는 벡터, 행렬 개념에 해당됩니다. 파이썬과 같은 프로그래밍 언어들은 배열을 기본적인 자료 구조로 제공하고 있고, NumPy 등의 라이브러리를 이용해서 숫자 배열 사이의 연산을 편리하게 할 수 있습니다. 또한, 데이터를 수학적인 행렬로 표현했을 때는 우리의 문제를 해결하는 최적의 모델을 찾는 과정에 선형대수학의 개념들을 적용할 수도 있죠. 그러므로 데이터를 배열 형태로 표현하는 것은 이론 측면에서도, 실제로 구현을 할 때도 효율적인 방법이라고 할 수 있습니다.\n인공지능, 특히 머신러닝 이론은 추론 통계학(inferential statistics)의 아이디어를 바탕으로 하고 있습니다. 우리가 알고 있는 데이터가 사실은 특정한 확률 분포로부터 관찰된 결과라는 것이죠. \n각각의 머신러닝 모델은 특정한 확률 분포(또는 확률 분포들 사이의 경계)를 나타내고 있기 때문에, 머신러닝 모델을 정의하고 학습시키는 데는 확률 개념이 포함됩니다. 모델의 종류와 구조는 확률 분포의 형태를 결정하고, 확률 분포의 세부적인 부분들은 모델의 파라미터(parameter, 매개 변수)에 의해 결정됩니다. 예를 들어 정규분포를 따르는 데이터로 모델을 학습시킨다고 합시다. 그러면 우리는 적절한 모델 구조를 선택함으로써 모델이 나타내는 확률 분포를 정규분포로 만들어주어야 하고, 주어진 데이터를 이용해 모델의 파라미터 값을 변경해서 정규분포의 평균과 표준편차를 데이터에 맞게 조절해주어야 합니다. 딥러닝 분야에서 자주 등장하는 용어인 하이퍼파라미터(hyperparameter) 역시 ‘모델의 구조’에 해당하는 개념입니다. 결국 머신러닝은 적절한 모델 구조를 먼저 정의하고 최적의 파라미터 값을 찾는 과정이라고 할 수 있습니다. 그렇다면 최적의 파라미터는 어떻게 찾을 수 있을까요?\n우리가 관찰하는 데이터에는 다양한 오류가 포함되어 있습니다. 측정 기구의 오차, 통신 과정에서의 데이터 손실 등 사람이 줄일 수 있는 오류도 있지만, 데이터가 가지고 있는 태생적인 노이즈(noise)도 존재합니다. 그렇기 때문에 데이터가 특정한 확률 분포로부터 관찰되었다고 해도, 모든 데이터가 그 분포에 정확하게 일치하는 것은 아닙니다. 또한, 모든 데이터에 정확하게 들어맞는 확률 분포를 추정하는 것 역시 불가능합니다. 그러므로 머신러닝 모델의 목표는 주어진 데이터가 관찰될 확률을 100%로 만드는 것이 아니라, 확률을 최대화하는 것입니다. 하지만 많은 파라미터를 가지고 있는 모델, 특히 딥러닝 모델의 손실 함수(loss function, 모델의 예측 결과와 정답 데이터의 차이를 나타내는 함수)는 매우 복잡하기 때문에 최적의 파라미터를 한번에 계산할 수가 없습니다. 그 대신, 파라미터를 여러 번에 걸쳐서 조금씩 업데이트하는 방법을 사용하죠. \n이 문제와 관련된 수학 분야가 바로 미적분입니다.\n미분은 함수에서 입력 변수의 변화량에 따른 출력 변수의 변화량을 나타내는 개념입니다. 머신러닝의 예를 들면 입력 변수는 데이터와 모델 파라미터, 출력 변수는 모델의 예측 결과로 생각할 수 있습니다. 그런데 모델을 학습시킬 때는 데이터가 이미 주어져 있으므로 데이터는 값이 변하는 변수가 아니고, 미분 개념은 파라미터의 변화량과 예측 값의 변화량 사이의 관계를 계산하는 데 사용됩니다. 모델의 예측 결과와 정답 데이터의 차이(오차)를 계산하는 것은 쉽기 때문에, 이 오차 값(출력)과 미분을 이용해서 모델 파라미터(입력)가 얼마나 변경되어야 오차가 줄어드는지 알아낼 수 있다.\n\n딥러닝에서의 학습은 훈련 데이터가 제시하는 연습 문제를 잘 해결하는 방향으로 신호를 전달하는 연결 지점에서 연결 강도를 변경하면서 이루어지는데(인간 뇌신경망의 연결 원리), 이때 연결 강도를 어떻게 변경해야 할지를 선형대수학과 다변수 함수의 편미분을 사용하여 구한다. 또한 기계학습 전반에 걸쳐서 다양한 종류의 최적화 문제가 등장하며 최적화 이론이 많이 활용된다.",
  "color": "default",
  "labels": [
    "53f6ec6c-841a-4ea4-a381-5d977aafd7cf",
    "5a9d5fc2-ea5e-4fcc-9ea8-e90e5cafee05",
    "9dde1e04-dd34-4201-bce0-c559b528d7a5"
  ],
  "pinned": false,
  "archived": true,
  "inTrash": false,
  "reminder": null,
  "createdAt": "2023-01-30T09:17:55.558000",
  "updatedAt": "2023-01-30T10:00:55.914000"
}